apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: "{{ .Release.Name }}-calico"
  namespace: "{{ .Release.Namespace }}"
  labels:
{{ include "labels" $ | indent 4 }}
    prometheus: "{{ .Release.Name }}"
    component: calico
spec:
  groups:
  - name: calico.rules
    rules:
    - alert: CalicoNodeInstanceDown
      expr: up{job="{{ .Release.Name }}-calico"} != 1
      for: 5m
      labels:
        severity: critical
      annotations:
        description: '{{`{{$labels.instance}}`}} of job {{`{{$labels.job}}`}} has been down for more than 5 minutes'
        summary: 'Instance {{`{{$labels.instance}}`}} Pod: {{`{{$labels.pod}}`}} is down'
        runbook_url: 'https://github.com/skyscrapers/documentation/tree/master/runbook.md#alert-name-caliconodeinstancedown'
    - alert: CalicoDataplaneFailures
      expr: felix_int_dataplane_failures{job="{{ .Release.Name }}-calico"} > 0
      for: 5m
      labels:
        severity: warning
      annotations:
        description: '{{`{{$labels.instance}}`}} with calico-node pod {{`{{$labels.pod}}`}} has been having dataplane failures'
        summary: 'Instance {{`{{$labels.instance}}`}} - Dataplane failures'
        runbook_url: 'https://github.com/skyscrapers/documentation/tree/master/runbook.md#alert-name-calicodataplanefailures'
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: "{{ .Release.Name }}-node-custom"
  namespace: "{{ .Release.Namespace }}"
  labels:
{{ include "labels" $ | indent 4 }}
    prometheus: "{{ .Release.Name }}"
spec:
  groups:
  - name: node-custom.rules
    rules:
    - alert: MemoryOvercommitted
      expr: round(((sum(kube_pod_container_resource_limits_memory_bytes) by (node) / sum(kube_node_status_capacity_memory_bytes ) by (node) )) *100) >=100
      for: 1h
      labels:
        severity: warning
      annotations:
        description: '{{`{{$labels.node}}`}} is overcommited by {{`{{$value}}`}}%'
        summary: 'Instance {{`{{$labels.node}}`}} Memory usage high'
        runbook_url: 'https://github.com/skyscrapers/documentation/tree/master/runbook.md#alert-name-memoryovercommitted'
    - alert: CPUUsageHigh
      expr: 100 * (1 - avg by(instance)(irate(node_cpu{mode='idle'}[1h]))) >= 90
      for: 5m
      labels:
        severity: warning
      annotations:
        description: '{{`{{$labels.instance}}`}} is using more than 90% CPU for >1h '
        summary: 'Instance {{`{{$labels.instance}}`}} CPU usage high'
        runbook_url: 'https://github.com/skyscrapers/documentation/tree/master/runbook.md#alert-name-cpuusagehigh'
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: "{{ .Release.Name }}-cronjob"
  namespace: "{{ .Release.Namespace }}"
  labels:
{{ include "labels" $ | indent 4 }}
    prometheus: "{{ .Release.Name }}"
spec:
  groups:
  - name: cronjobs.rules
    rules:
    - record: job_cronjob:kube_job_status_start_time:max                                                                  
      expr: |
        label_replace(
          label_replace(
            max(
              kube_job_status_start_time
              * ON(job_name, namespace) GROUP_RIGHT()
              kube_job_labels{label_cronjob!=""}
            ) BY (job_name, namespace, label_cronjob)
            == ON(label_cronjob) GROUP_LEFT()
            max(
              kube_job_status_start_time
              * ON(job_name, namespace) GROUP_RIGHT()
              kube_job_labels{label_cronjob!=""}
            ) BY (label_cronjob),
            "job", "$1", "job_name", "(.+)"),
          "cronjob", "$1", "label_cronjob", "(.+)")
    - record: job_cronjob:kube_job_status_not_succeed:sum
      expr: |
        clamp_max(
          job_cronjob:kube_job_status_start_time:max,
        1)
        * ON(job) GROUP_LEFT()
        label_replace(
          label_replace(
            (kube_job_status_succeeded == 0),
            "job", "$1", "job_name", "(.+)"),
          "cronjob", "$1", "label_cronjob", "(.+)")
    - alert: CronJobFailures
      expr: |
        job_cronjob:kube_job_status_not_succeed:sum
        == 0
      for: 1m
      labels:
        severity: critical
        group: cronjobs
      annotations:
        description: '{{ `{{ $labels.cronjob }}` }} last run did not succeed.'
